---
title: "Database_Build"
author: "Jake Eisaguirre"
date: "2022-09-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}

# librarian downloads, if not already downloaded, and reads in needed packages
librarian::shelf(tidyverse, here, janitor, lubridate, RPostgres, rstudioapi, DBI, parsedate, stringr, hms)
```

# create location table (panama, brazil, usa)
```{r}

location_table <- data.frame(c("panama", "brazil", "usa"))

colnames(location_table) <- c("location")

write_csv(location_table, here("clean_tables", "location.csv"))
```


# create region table

## manually create USA regions
```{r}

usa_regions <- data.frame(c("pennsylvania", "vermont", "new mexico", "tennessee", "louisiana", "california"),
                          c("usa", "usa", "usa", "usa", "usa", "usa"))

colnames(usa_regions) <- c("region", "location")

```

## read in panama legacy data and pull out regions
```{r}

panama_raw <- read_csv(here("data", "panama_legacy", "panama_data.csv")) %>% 
  clean_names()

panama_regions <- panama_raw %>% 
  mutate(region = str_to_lower(region),
         location = "panama") %>% 
  select(region, location) %>% 
  unique()
```

## manually create brazil legacy data region (santa virginia)
```{r}

brazil_regions <- data.frame(c("santa virginia"), c("brazil"))

colnames(brazil_regions) <- c("region", "location")

```

## combine region tables
```{r}

regions <- rbind(brazil_regions, panama_regions, usa_regions)

write_csv(regions, here("clean_tables", "regions.csv"))
```


# create site table 

## pull out panama sites
```{r}

panama_sites <- panama_raw %>% 
  mutate(region = str_to_lower(region),
         site = str_to_lower(site),
         location = "panama") %>% 
  select(region, site, location) %>% 
  unique()

```

## pull out serdp sites
```{r}

serdp_sites <- read_csv(here("data", "serdp", "serdp_site_table.csv")) %>% 
  clean_names() %>% 
  rename(site_comments = notes,
         region = dod_location) %>% 
  # align serdp site names with current penn site names
  mutate(site_name = str_to_lower(site_name),
         site_name = if_else(site_name == "wood lab", "wood lab pond", site_name),
         site_name = if_else(site_name == "rv", "rv pond", site_name),
         site_name = if_else(site_name == "tuttle", "tuttle pond", site_name),
         site_name = if_else(site_name == "phelps", "phelps pond", site_name),
         site_name = if_else(site_name == "newt (mike vorisek's)", "vorisek pond", site_name),
         location = "usa",
         region = if_else(region == "pa", "pennsylvania", region),
         region = if_else(region == "tn", "tennessee", region),
         region = if_else(region == "vt", "vermont", region),
         region = if_else(region == "nm", "new mexico", region),
         region = if_else(region == "la", "louisiana", region)) %>% 
  select(!c(site_code, t_id)) %>% 
  rename(site_code = site,
         site = site_name)

```

## load penn ribbitr sites
```{r}
penn_sites <- read_csv(here("data", "penn", "penn_sites.csv")) %>% 
  clean_names() %>% 
  select(!c(observer,date)) %>% 
  mutate(region = "pennsylvania")
```
## pull out brazil legacy sites
```{r}

brazil_legacy_sites <- read_csv(here("data", "brazil_legacy", "brazil_site.csv")) %>% 
  unite(site, area:environment, sep = " ") %>% 
  rename(lat = latitude_start,
         long = longitude_start) %>% 
  select(!c(latitude_end, longitude_end)) %>% 
  mutate(region = "santa virginia",
         location = "brazil")

```
## combine site tables
```{r}

sites <- plyr::rbind.fill(brazil_legacy_sites, penn_sites, serdp_sites, panama_sites) %>% 
  mutate(site = str_replace_all(site, " ", "_"),
         region = str_replace_all(region, " ", "_"),
         site = str_remove(site, "-"),
         site = str_remove(site, "\\.")) %>% 
  group_by(site) %>%
   mutate(across(everything(), ~ .x[order(.x)])) %>%
   slice_head(n = 1) %>%
   ungroup()
  
write_csv(sites, here("clean_tables", "sites.csv"))
```

# create visit table

## pull out unique visits for penn1 ribbitr

### load all year 1 penn data
```{r}
munged_Amphibian_Processing_App <- read_csv(here("data", "penn", "munged_Amphibian_Processing_App.csv"))

munged_Amphibian_Captured_Information <-  read_csv(here("data", "penn","munged_Amphibian_Captured_Information.csv"))
                       
munged_Amphibian_Captured_Information_Repeatable <- read_csv(here("data","penn", "munged_Amphibian_Captured_Information_Repeatable.csv"))

munged_Amphibian_Processing_App_Repeatable <- read_csv(here("data", "penn","munged_Amphibian_Processing_App_Repeatable.csv"))

munged_VisualEncounter_Survey <- read_csv(here("data", "penn","munged_VisualEncounter_Survey.csv"))
  
munged_VisualEncounter_Survey_Repeatable <- read_csv(here("data", "penn","munged_VisualEncounter_Survey_Repeatable.csv"))

munged_Acoustic_Survey <- read_csv(here("data", "penn","munged_Acoustic_Survey.csv"))

munged_Acoustic_Survey_Repeatable <- read_csv(here("data", "penn","munged_Acoustic_Survey_Repeatable.csv"))


```

### join different fulcrum app forms per survey

#### capture
```{r}

penn1_capture <- right_join(right_join(munged_Amphibian_Captured_Information,
                                                        munged_Amphibian_Captured_Information_Repeatable, 
                                                        by = c("fulcrum_id" = "fulcrum_parent_id")),
                                            right_join(munged_Amphibian_Processing_App,
                                                       munged_Amphibian_Processing_App_Repeatable, 
                                                       by =c('fulcrum_id' = 'fulcrum_parent_id')),
                                            by = c('location', 'date', 'bag_id')) %>% 
  select(!c( "fulcrum_id.x", "created_at.x.x", "fulcrum_id.y.x", "created_at.y.x", 
            "fulcrum_id.y.y", "created_at.x.y", "fulcrum_id.y.y.y","created_at.y.y", "time_of_capture.y", 
            "body_temperature.y", "microhabitat_type.y","microhabitat_temperature.y", "observer_other", "processor_other",
            "capture_type_other", "sex_other", "species")) %>% 
  rename(survey_comment = survey_comments.x,
         visit_comment = survey_comments.y,
         time_of_capture = time_of_capture.x,
         body_temperature_c = body_temperature.x,
         microhabitat_type = microhabitat_type.x,
         microhabitat_temperature_c = microhabitat_temperature.x,
         site = location) %>% 
  mutate(date = parse_date(date),
         observer = str_to_lower(observer),
         site = str_to_lower(site),
         bag_id = str_to_lower(bag_id),
         microhabitat_type = str_to_lower(microhabitat_type),
         processor = str_to_lower(processor),
         capture_type = str_to_lower(capture_type),
         life_stage = str_to_lower(life_stage),
         species_capture = str_to_lower(species_capture),
         sex = str_to_lower(sex)) %>% 
  unique() %>% 
    mutate(start_hour = hour(start_time),
         end_hour = hour(end_time),
         survey_time = case_when(start_hour >= 6 & end_hour >= 6 & end_hour < 19 ~ "day", 
                          start_hour >= 19 &  (end_hour < 6 | end_hour <= 23) |
                         (start_hour < 6 & end_hour < 6)~ "night",
                         start_hour >=19 ~"night")) %>% 
  select(!c(start_hour, end_hour)) %>% 
  mutate(species_capture = paste(species_capture, species_capture_other, sep = ""),
         species_capture = str_replace(species_capture, "NA", ""),
         region = "pa",
         location = "usa",
         detection_type = "capture") %>% 
  select(!c(species_capture_other))%>% 
  mutate(survey_time = if_else(is.na(survey_time), "night", survey_time))



```

#### VES
```{r}

penn1_VES <- left_join(munged_VisualEncounter_Survey, munged_VisualEncounter_Survey_Repeatable, 
                       by = c('fulcrum_id' = 'fulcrum_parent_id')) %>% 
  select(observer, date, location, start_time, end_time, species_ves, count_ves, comments_ves) %>%
  unique() %>%
  drop_na(species_ves) %>% 
  mutate(observer = str_to_lower(observer),
         date = parse_date(date),
         location = str_to_lower(location),
         species_ves = str_to_lower(species_ves),
         comments_ves = str_to_lower(comments_ves)) %>% 
  rename(count = count_ves,
         site = location) %>% 
      mutate(start_hour = hour(start_time),
         end_hour = hour(end_time),
         survey_time = case_when(start_hour >= 6 & end_hour >= 6 & end_hour < 19 ~ "day", 
                          start_hour >= 19 &  (end_hour < 6 | end_hour <= 23) |
                         (start_hour < 6 & end_hour < 6)~ "night",
                         start_hour >=19 ~"night"),
         region = "pa",
         location = "usa",
         detection_type = "visual") %>% 
  select(!c(start_hour, end_hour))%>% 
  mutate(survey_time = if_else(is.na(survey_time), "night", survey_time),
         site = if_else(is.na(site), "phelps pond", site))


```

#### aural
```{r}
penn1_aural <-left_join(munged_Acoustic_Survey, munged_Acoustic_Survey_Repeatable, by = c('fulcrum_id' = 'fulcrum_parent_id')) %>%
  select(observer, date, location, start_time, end_time, species_acoustic, call_index, acoustic_comments) %>%
  unique() %>%
  mutate(observer = str_to_lower(observer),
         date = parse_date(date),
         location = str_to_lower(location),
         species_acoustic = str_to_lower(species_acoustic),
         call_index = str_to_lower(call_index),
         acoustic_comments = str_to_lower(acoustic_comments)) %>% 
  rename(site = location) %>% 
  mutate(duration_min = if_else(end_time < start_time,
                            as_hms(86400) - start_time + end_time,
                            end_time - start_time),
         duration_min = duration_min/60,
         detection_type = "acoustic",
          region = "pa",
         location = "usa",
         start_hour = hour(start_time),
         end_hour = hour(end_time),
         survey_time = case_when(start_hour >= 6 & end_hour >= 6 & end_hour < 19 ~ "day", 
                          start_hour >= 19 &  (end_hour < 6 | end_hour <= 23) |
                         (start_hour < 6 & end_hour < 6)~ "night",
                         start_hour >=19 ~"night")) %>%
  relocate(duration_min, .before = species_acoustic)

penn1_aural$duration_min <- str_sub(penn1_aural$duration_min, -4) %>% 
  as.numeric()
```

### pull out visits based on date and survey_time(night/day) for VES, aural, and capture
```{r}
penn1_VES_visit <- penn1_VES %>% 
  select(date, survey_time, site, detection_type)

penn1_capture_visit <- penn1_capture %>% 
  select(date, survey_time, site, detection_type)

penn1_aural_visit <- penn1_aural %>% 
  select(date, survey_time, site, detection_type)
```

### bind all penn1 visits and filter for duplicated uniqueness based on date, survey_time, and site to get true penn1 visit table
```{r}

penn_visit_table <- plyr::rbind.fill(penn1_aural_visit, penn1_VES_visit, penn1_capture_visit) %>% 
  group_by(date, survey_time, site) %>% 
  mutate(temp_id = cur_group_id()) %>% 
  filter(!duplicated(temp_id)) %>% 
  select(!c(detection_type, temp_id))

```

## read in serdp unique visits - need to either read in all data and format sites as above or adjust in different script. Either method is fine since data will not be changing
```{r}



```

